{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Basic Neural Network \n",
    "# with Higher-level TF Wrappers (Estimators, Layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicated from [Aymeric Damien's TF `neural_network` Example](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/neural_network.ipynb)\n",
    "\n",
    "Basic multi-layer perceptron neural network, with TensorFlow's higher-level wrappers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we're useing `one_hot=`**`False`**  here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_steps = 5000\n",
    "batch_size = 128\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 256  # number of neurons\n",
    "n_hidden_2 = 256\n",
    "num_input = 28**2\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF input functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job of an input function is to deliver data (as numpy array or pandas dataframe) to a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'images': mnist.train.images},\n",
    "    y = mnist.train.labels,\n",
    "    batch_size = batch_size,\n",
    "    num_epochs = None,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network is essentially a chain of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net(x_dict):\n",
    "    x = x_dict['images']\n",
    "    layer_1 = tf.layers.dense(inputs=x, units=n_hidden_1)\n",
    "    layer_2 = tf.layers.dense(inputs=layer_1, units=n_hidden_2)\n",
    "    out_layer = tf.layers.dense(inputs=layer_2, units=num_classes)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What the hell is an `EstimatorSpec`???***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas  = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=pred_classes)\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                                            labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    estim_specs = tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                             predictions=pred_classes,\n",
    "                                             loss=loss_op,\n",
    "                                             train_op=train_op,\n",
    "                                             eval_metric_ops = {'accuracy': acc_op}\n",
    "                                            )\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/n_/yc8w5lvd0939ndnjzj5wm8mr0000gn/T/tmpqqujfk0w\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/n_/yc8w5lvd0939ndnjzj5wm8mr0000gn/T/tmpqqujfk0w', '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn=model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/n_/yc8w5lvd0939ndnjzj5wm8mr0000gn/T/tmpqqujfk0w/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.32305, step = 1\n",
      "INFO:tensorflow:global_step/sec: 154.395\n",
      "INFO:tensorflow:loss = 0.541347, step = 101 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.446\n",
      "INFO:tensorflow:loss = 0.371348, step = 201 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.697\n",
      "INFO:tensorflow:loss = 0.298337, step = 301 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.507\n",
      "INFO:tensorflow:loss = 0.201261, step = 401 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.896\n",
      "INFO:tensorflow:loss = 0.385448, step = 501 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.023\n",
      "INFO:tensorflow:loss = 0.456829, step = 601 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.316\n",
      "INFO:tensorflow:loss = 0.216312, step = 701 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.474\n",
      "INFO:tensorflow:loss = 0.45164, step = 801 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.237\n",
      "INFO:tensorflow:loss = 0.287792, step = 901 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.884\n",
      "INFO:tensorflow:loss = 0.224974, step = 1001 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.522\n",
      "INFO:tensorflow:loss = 0.245597, step = 1101 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.022\n",
      "INFO:tensorflow:loss = 0.22238, step = 1201 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.136\n",
      "INFO:tensorflow:loss = 0.286079, step = 1301 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.656\n",
      "INFO:tensorflow:loss = 0.353559, step = 1401 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.831\n",
      "INFO:tensorflow:loss = 0.400064, step = 1501 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.013\n",
      "INFO:tensorflow:loss = 0.256745, step = 1601 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.907\n",
      "INFO:tensorflow:loss = 0.260791, step = 1701 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.384\n",
      "INFO:tensorflow:loss = 0.212779, step = 1801 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.399\n",
      "INFO:tensorflow:loss = 0.424887, step = 1901 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.347\n",
      "INFO:tensorflow:loss = 0.275724, step = 2001 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.527\n",
      "INFO:tensorflow:loss = 0.243173, step = 2101 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.479\n",
      "INFO:tensorflow:loss = 0.173499, step = 2201 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.109\n",
      "INFO:tensorflow:loss = 0.284071, step = 2301 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.385\n",
      "INFO:tensorflow:loss = 0.308309, step = 2401 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.592\n",
      "INFO:tensorflow:loss = 0.34192, step = 2501 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.078\n",
      "INFO:tensorflow:loss = 0.284431, step = 2601 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.513\n",
      "INFO:tensorflow:loss = 0.558474, step = 2701 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.1\n",
      "INFO:tensorflow:loss = 0.249631, step = 2801 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.922\n",
      "INFO:tensorflow:loss = 0.321351, step = 2901 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.742\n",
      "INFO:tensorflow:loss = 0.148996, step = 3001 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.43\n",
      "INFO:tensorflow:loss = 0.24541, step = 3101 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.119\n",
      "INFO:tensorflow:loss = 0.242027, step = 3201 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.364\n",
      "INFO:tensorflow:loss = 0.293884, step = 3301 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.501\n",
      "INFO:tensorflow:loss = 0.268274, step = 3401 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.732\n",
      "INFO:tensorflow:loss = 0.349266, step = 3501 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.779\n",
      "INFO:tensorflow:loss = 0.189378, step = 3601 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.578\n",
      "INFO:tensorflow:loss = 0.140976, step = 3701 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.134\n",
      "INFO:tensorflow:loss = 0.181297, step = 3801 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.896\n",
      "INFO:tensorflow:loss = 0.277393, step = 3901 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.15\n",
      "INFO:tensorflow:loss = 0.280561, step = 4001 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.704\n",
      "INFO:tensorflow:loss = 0.19047, step = 4101 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.543\n",
      "INFO:tensorflow:loss = 0.272555, step = 4201 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.654\n",
      "INFO:tensorflow:loss = 0.398388, step = 4301 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.481\n",
      "INFO:tensorflow:loss = 0.216779, step = 4401 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.522\n",
      "INFO:tensorflow:loss = 0.277105, step = 4501 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.997\n",
      "INFO:tensorflow:loss = 0.249181, step = 4601 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.216\n",
      "INFO:tensorflow:loss = 0.274381, step = 4701 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.702\n",
      "INFO:tensorflow:loss = 0.286552, step = 4801 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.772\n",
      "INFO:tensorflow:loss = 0.440011, step = 4901 (0.655 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/n_/yc8w5lvd0939ndnjzj5wm8mr0000gn/T/tmpqqujfk0w/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.261698.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x128b25828>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={'images': mnist.test.images},\n",
    "                                                   y = mnist.test.labels,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=False\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-12-26-05:53:05\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/n_/yc8w5lvd0939ndnjzj5wm8mr0000gn/T/tmpqqujfk0w/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-26-05:53:05\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9223, global_step = 5000, loss = 0.279789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.92229998, 'global_step': 5000, 'loss': 0.27978891}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 3\n",
    "pick = np.random.randint(mnist.test.labels.shape[0], size=n_images)\n",
    "\n",
    "test_images = np.array([mnist.test.images[i] for i in pick])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/n_/yc8w5lvd0939ndnjzj5wm8mr0000gn/T/tmpqqujfk0w/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "pred_input_func = tf.estimator.inputs.numpy_input_fn(x={'images': test_images}, shuffle=False)\n",
    "\n",
    "preds = list(model.predict(input_fn=pred_input_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f921048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUv8F244McAW4yAwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f9f7898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMvxSUYZfKsrwS0X9P0Ie8nQwUfD4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f777e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28,28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print('Model prediction:', preds[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
